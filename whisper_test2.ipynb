{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\atusi\\appdata\\local\\temp\\pip-req-build-dgoftk5v\n",
      "  Resolved https://github.com/openai/whisper.git to commit e8622f9afc4eba139bf796c210f5c01081000472\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: more-itertools in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from openai-whisper==20230314) (10.0.0)\n",
      "Requirement already satisfied: tiktoken==0.3.3 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from openai-whisper==20230314) (0.3.3)\n",
      "Requirement already satisfied: torch in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from openai-whisper==20230314) (2.0.0+cu117)\n",
      "Requirement already satisfied: tqdm in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from openai-whisper==20230314) (4.65.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from openai-whisper==20230314) (1.24.3)\n",
      "Requirement already satisfied: numba in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from openai-whisper==20230314) (0.57.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2023.6.3)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from numba->openai-whisper==20230314) (0.40.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from torch->openai-whisper==20230314) (3.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from torch->openai-whisper==20230314) (3.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from tqdm->openai-whisper==20230314) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from jinja2->torch->openai-whisper==20230314) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from sympy->torch->openai-whisper==20230314) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\atusi\\AppData\\Local\\Temp\\pip-req-build-dgoftk5v'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] 指定されたファイルが見つかりません。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\atusi\\OneDrive\\ドキュメント\\研究関連（修士）\\Github\\sibuya\\whisper_test2.ipynb セル 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atusi/OneDrive/%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88/%E7%A0%94%E7%A9%B6%E9%96%A2%E9%80%A3%EF%BC%88%E4%BF%AE%E5%A3%AB%EF%BC%89/Github/sibuya/whisper_test2.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m whisper\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39msmall\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/atusi/OneDrive/%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88/%E7%A0%94%E7%A9%B6%E9%96%A2%E9%80%A3%EF%BC%88%E4%BF%AE%E5%A3%AB%EF%BC%89/Github/sibuya/whisper_test2.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtranscribe(\u001b[39m\"\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mdvd.mp3\u001b[39;49m\u001b[39m\"\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atusi/OneDrive/%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88/%E7%A0%94%E7%A9%B6%E9%96%A2%E9%80%A3%EF%BC%88%E4%BF%AE%E5%A3%AB%EF%BC%89/Github/sibuya/whisper_test2.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(result[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\whisper\\transcribe.py:121\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, **decode_options)\u001b[0m\n\u001b[0;32m    118\u001b[0m     decode_options[\u001b[39m\"\u001b[39m\u001b[39mfp16\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m mel \u001b[39m=\u001b[39m log_mel_spectrogram(audio, padding\u001b[39m=\u001b[39;49mN_SAMPLES)\n\u001b[0;32m    122\u001b[0m content_frames \u001b[39m=\u001b[39m mel\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m N_FRAMES\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m decode_options\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\whisper\\audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[1;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(audio):\n\u001b[0;32m    139\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(audio, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 140\u001b[0m         audio \u001b[39m=\u001b[39m load_audio(audio)\n\u001b[0;32m    141\u001b[0m     audio \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(audio)\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\whisper\\audio.py:59\u001b[0m, in \u001b[0;36mload_audio\u001b[1;34m(file, sr)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39m# fmt: on\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     out \u001b[39m=\u001b[39m run(cmd, capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mstdout\n\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m CalledProcessError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to load audio: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mdecode()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m    503\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 505\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    506\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    507\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    947\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m    948\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    949\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    952\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    953\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    954\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    955\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    956\u001b[0m                         errread, errwrite,\n\u001b[0;32m    957\u001b[0m                         restore_signals,\n\u001b[0;32m    958\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m    959\u001b[0m                         start_new_session)\n\u001b[0;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\subprocess.py:1420\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1418\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   1419\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1420\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1421\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1422\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1423\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1424\u001b[0m                              creationflags,\n\u001b[0;32m   1425\u001b[0m                              env,\n\u001b[0;32m   1426\u001b[0m                              cwd,\n\u001b[0;32m   1427\u001b[0m                              startupinfo)\n\u001b[0;32m   1428\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1429\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1433\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1436\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1437\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 指定されたファイルが見つかりません。"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"small\")\n",
    "result = model.transcribe(\"C:\\dvd.mp3\", verbose=True)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# いくぞ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faster-whisper\n",
      "  Downloading faster_whisper-0.7.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 7.0 MB/s eta 0:00:00\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
      "     ---------------------------------------- 7.5/7.5 MB 11.7 MB/s eta 0:00:00\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-win_amd64.whl (977 kB)\n",
      "     ------------------------------------- 977.6/977.6 kB 10.4 MB/s eta 0:00:00\n",
      "Collecting onnxruntime<2,>=1.14\n",
      "  Downloading onnxruntime-1.15.1-cp39-cp39-win_amd64.whl (6.7 MB)\n",
      "     ---------------------------------------- 6.7/6.7 MB 9.0 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.13\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "     -------------------------------------- 268.8/268.8 kB 8.1 MB/s eta 0:00:00\n",
      "Collecting ctranslate2<4,>=3.17\n",
      "  Downloading ctranslate2-3.18.0-cp39-cp39-win_amd64.whl (20.1 MB)\n",
      "     --------------------------------------- 20.1/20.1 MB 11.1 MB/s eta 0:00:00\n",
      "Collecting tokenizers==0.13.*\n",
      "  Using cached tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "Collecting av==10.*\n",
      "  Downloading av-10.0.0-cp39-cp39-win_amd64.whl (25.3 MB)\n",
      "     --------------------------------------- 25.3/25.3 MB 11.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.3-cp39-cp39-win_amd64.whl (266 kB)\n",
      "     -------------------------------------- 266.4/266.4 kB 8.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from huggingface-hub>=0.13->faster-whisper) (4.5.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from huggingface-hub>=0.13->faster-whisper) (2023.4.0)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 kB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.11.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from onnxruntime<2,>=1.14->faster-whisper) (23.5.26)\n",
      "Requirement already satisfied: protobuf in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from onnxruntime<2,>=1.14->faster-whisper) (4.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 kB 4.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.2.1)\n",
      "Collecting pyreadline3\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 95.2/95.2 kB 5.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, pyreadline3, av, humanfriendly, ctranslate2, huggingface-hub, coloredlogs, transformers, onnxruntime, faster-whisper\n",
      "Successfully installed av-10.0.0 coloredlogs-15.0.1 ctranslate2-3.18.0 faster-whisper-0.7.1 huggingface-hub-0.16.4 humanfriendly-10.0 onnxruntime-1.15.1 pyreadline3-3.4.1 safetensors-0.3.3 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.32.0\n",
      "Collecting yt-dlp\n",
      "  Downloading yt_dlp-2023.7.6-py2.py3-none-any.whl (3.0 MB)\n",
      "     ---------------------------------------- 3.0/3.0 MB 11.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi in c:\\users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages (from yt-dlp) (2022.12.7)\n",
      "Collecting brotli\n",
      "  Downloading Brotli-1.0.9-cp39-cp39-win_amd64.whl (383 kB)\n",
      "     ------------------------------------- 383.4/383.4 kB 12.0 MB/s eta 0:00:00\n",
      "Collecting pycryptodomex\n",
      "  Downloading pycryptodomex-3.18.0-cp35-abi3-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 11.1 MB/s eta 0:00:00\n",
      "Collecting websockets\n",
      "  Downloading websockets-11.0.3-cp39-cp39-win_amd64.whl (124 kB)\n",
      "     -------------------------------------- 124.7/124.7 kB 7.2 MB/s eta 0:00:00\n",
      "Collecting mutagen\n",
      "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
      "     -------------------------------------- 193.6/193.6 kB 5.9 MB/s eta 0:00:00\n",
      "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, yt-dlp\n",
      "Successfully installed brotli-1.0.9 mutagen-1.46.0 pycryptodomex-3.18.0 websockets-11.0.3 yt-dlp-2023.7.6\n"
     ]
    }
   ],
   "source": [
    "!pip install faster-whisper transformers sentencepiece\n",
    "!python -m pip install -U yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/live/outcGtbnMuQ?feature=share\n",
      "[youtube] outcGtbnMuQ: Downloading webpage\n",
      "[youtube] outcGtbnMuQ: Downloading ios player API JSON\n",
      "[youtube] outcGtbnMuQ: Downloading android player API JSON\n",
      "[youtube] outcGtbnMuQ: Downloading m3u8 information\n",
      "[info] outcGtbnMuQ: Downloading 1 format(s): 251\n",
      "[download] Destination: audio.webm\n",
      "\n",
      "[download]   0.0% of   17.93MiB at  190.27KiB/s ETA 01:36\n",
      "[download]   0.0% of   17.93MiB at  478.64KiB/s ETA 00:38\n",
      "[download]   0.0% of   17.93MiB at    1.09MiB/s ETA 00:16\n",
      "[download]   0.1% of   17.93MiB at    2.02MiB/s ETA 00:08\n",
      "[download]   0.2% of   17.93MiB at    1.61MiB/s ETA 00:11\n",
      "[download]   0.3% of   17.93MiB at    1.87MiB/s ETA 00:09\n",
      "[download]   0.7% of   17.93MiB at    2.66MiB/s ETA 00:06\n",
      "[download]   1.4% of   17.93MiB at    3.75MiB/s ETA 00:04\n",
      "[download]   2.8% of   17.93MiB at    5.40MiB/s ETA 00:03\n",
      "[download]   5.6% of   17.93MiB at    6.04MiB/s ETA 00:02\n",
      "[download]  11.2% of   17.93MiB at    8.64MiB/s ETA 00:01\n",
      "[download]  22.3% of   17.93MiB at    9.40MiB/s ETA 00:01\n",
      "[download]  44.6% of   17.93MiB at   10.40MiB/s ETA 00:00\n",
      "[download]  55.1% of   17.93MiB at   10.49MiB/s ETA 00:00\n",
      "[download]  55.1% of   17.93MiB at  212.36KiB/s ETA 00:38\n",
      "[download]  55.1% of   17.93MiB at  574.85KiB/s ETA 00:14\n",
      "[download]  55.2% of   17.93MiB at    1.31MiB/s ETA 00:06\n",
      "[download]  55.2% of   17.93MiB at    2.81MiB/s ETA 00:02\n",
      "[download]  55.3% of   17.93MiB at    1.75MiB/s ETA 00:04\n",
      "[download]  55.5% of   17.93MiB at    2.07MiB/s ETA 00:03\n",
      "[download]  55.8% of   17.93MiB at    2.66MiB/s ETA 00:02\n",
      "[download]  56.5% of   17.93MiB at    3.97MiB/s ETA 00:01\n",
      "[download]  57.9% of   17.93MiB at    5.77MiB/s ETA 00:01\n",
      "[download]  60.7% of   17.93MiB at    6.85MiB/s ETA 00:01\n",
      "[download]  66.3% of   17.93MiB at    8.18MiB/s ETA 00:00\n",
      "[download]  77.4% of   17.93MiB at    9.34MiB/s ETA 00:00\n",
      "[download]  99.7% of   17.93MiB at   10.54MiB/s ETA 00:00\n",
      "[download] 100.0% of   17.93MiB at   10.56MiB/s ETA 00:00\n",
      "[download] 100% of   17.93MiB in 00:00:01 at 9.78MiB/s   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
     ]
    }
   ],
   "source": [
    "!yt-dlp -x --audio-format mp3 https://www.youtube.com/live/outcGtbnMuQ?feature=share -o audio.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'en' with probability 0.998047\n",
      "[0.000000s -> 12.360000s]  to the GPT-4 developer demo livestream.\n",
      "[12.360000s -> 13.800000s]  Honestly, it's kind of hard for me\n",
      "[13.800000s -> 15.400000s]  to believe that this day is here.\n",
      "[15.400000s -> 18.280000s]  OpenAI has been building this technology really\n",
      "[18.280000s -> 19.680000s]  since we started the company.\n",
      "[19.680000s -> 21.080000s]  But for the past two years, we've\n",
      "[21.080000s -> 24.080000s]  been really focused on delivering GPT-4.\n",
      "[24.080000s -> 27.420000s]  That started with rebuilding our entire training stack,\n",
      "[27.420000s -> 29.560000s]  actually training the model, and then\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA failed with error out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\atusi\\OneDrive\\ドキュメント\\研究関連（修士）\\Github\\sibuya\\whisper_test2.ipynb セル 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atusi/OneDrive/%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88/%E7%A0%94%E7%A9%B6%E9%96%A2%E9%80%A3%EF%BC%88%E4%BF%AE%E5%A3%AB%EF%BC%89/Github/sibuya/whisper_test2.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m segments, info \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtranscribe(\u001b[39m\"\u001b[39m\u001b[39maudio.webm\u001b[39m\u001b[39m\"\u001b[39m, beam_size\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/atusi/OneDrive/%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88/%E7%A0%94%E7%A9%B6%E9%96%A2%E9%80%A3%EF%BC%88%E4%BF%AE%E5%A3%AB%EF%BC%89/Github/sibuya/whisper_test2.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDetected language \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with probability \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (info\u001b[39m.\u001b[39mlanguage, info\u001b[39m.\u001b[39mlanguage_probability))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/atusi/OneDrive/%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88/%E7%A0%94%E7%A9%B6%E9%96%A2%E9%80%A3%EF%BC%88%E4%BF%AE%E5%A3%AB%EF%BC%89/Github/sibuya/whisper_test2.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m segment \u001b[39min\u001b[39;00m segments:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/atusi/OneDrive/%E3%83%89%E3%82%AD%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%88/%E7%A0%94%E7%A9%B6%E9%96%A2%E9%80%A3%EF%BC%88%E4%BF%AE%E5%A3%AB%EF%BC%89/Github/sibuya/whisper_test2.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m%.6f\u001b[39;00m\u001b[39ms -> \u001b[39m\u001b[39m%.6f\u001b[39;00m\u001b[39ms] \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (segment\u001b[39m.\u001b[39mstart, segment\u001b[39m.\u001b[39mend, segment\u001b[39m.\u001b[39mtext))\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\faster_whisper\\transcribe.py:403\u001b[0m, in \u001b[0;36mWhisperModel.generate_segments\u001b[1;34m(self, features, tokenizer, options, encoder_output)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39mif\u001b[39;00m encoder_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    396\u001b[0m     encoder_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode(segment)\n\u001b[0;32m    398\u001b[0m (\n\u001b[0;32m    399\u001b[0m     result,\n\u001b[0;32m    400\u001b[0m     avg_logprob,\n\u001b[0;32m    401\u001b[0m     temperature,\n\u001b[0;32m    402\u001b[0m     compression_ratio,\n\u001b[1;32m--> 403\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_with_fallback(encoder_output, prompt, tokenizer, options)\n\u001b[0;32m    405\u001b[0m \u001b[39mif\u001b[39;00m options\u001b[39m.\u001b[39mno_speech_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    406\u001b[0m     \u001b[39m# no voice activity check\u001b[39;00m\n\u001b[0;32m    407\u001b[0m     should_skip \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mno_speech_prob \u001b[39m>\u001b[39m options\u001b[39m.\u001b[39mno_speech_threshold\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\faster_whisper\\transcribe.py:604\u001b[0m, in \u001b[0;36mWhisperModel.generate_with_fallback\u001b[1;34m(self, encoder_output, prompt, tokenizer, options)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    599\u001b[0m     kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    600\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbeam_size\u001b[39m\u001b[39m\"\u001b[39m: options\u001b[39m.\u001b[39mbeam_size,\n\u001b[0;32m    601\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpatience\u001b[39m\u001b[39m\"\u001b[39m: options\u001b[39m.\u001b[39mpatience,\n\u001b[0;32m    602\u001b[0m     }\n\u001b[1;32m--> 604\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mgenerate(\n\u001b[0;32m    605\u001b[0m     encoder_output,\n\u001b[0;32m    606\u001b[0m     [prompt],\n\u001b[0;32m    607\u001b[0m     length_penalty\u001b[39m=\u001b[39moptions\u001b[39m.\u001b[39mlength_penalty,\n\u001b[0;32m    608\u001b[0m     max_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length,\n\u001b[0;32m    609\u001b[0m     return_scores\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    610\u001b[0m     return_no_speech_prob\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    611\u001b[0m     suppress_blank\u001b[39m=\u001b[39moptions\u001b[39m.\u001b[39msuppress_blank,\n\u001b[0;32m    612\u001b[0m     suppress_tokens\u001b[39m=\u001b[39moptions\u001b[39m.\u001b[39msuppress_tokens,\n\u001b[0;32m    613\u001b[0m     max_initial_timestamp_index\u001b[39m=\u001b[39mmax_initial_timestamp_index,\n\u001b[0;32m    614\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    615\u001b[0m )[\u001b[39m0\u001b[39m]\n\u001b[0;32m    617\u001b[0m tokens \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39msequences_ids[\u001b[39m0\u001b[39m]\n\u001b[0;32m    619\u001b[0m \u001b[39m# Recover the average log prob from the returned score.\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA failed with error out of memory"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model_size = \"large-v2\"\n",
    "\n",
    "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "segments, info = model.transcribe(\"audio.webm\", beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.6fs -> %.6fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating duration from bitrate, this may be inaccurate\n",
      "100%|██████████| 83.0955/83.0955 [00:43<00:00,  1.91 audio seconds/s]\n"
     ]
    }
   ],
   "source": [
    "import faster_whisper\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = faster_whisper.WhisperModel(\"large-v2\", device=\"cuda\")\n",
    "\n",
    "def convert_to_hms(seconds: float) -> str:\n",
    "    hours, remainder = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    milliseconds = math.floor((seconds % 1) * 1000)\n",
    "    output = f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02},{milliseconds:03}\"\n",
    "    return output\n",
    "\n",
    "def convert_seg(segment: faster_whisper.transcribe.Segment) -> str:\n",
    "    return f\"{convert_to_hms(segment.start)} --> {convert_to_hms(segment.end)}\\n{segment.text.lstrip()}\\n\\n\"\n",
    "\n",
    "segments, info = model.transcribe(\"dvd.mp3\")\n",
    "\n",
    "full_txt = []\n",
    "timestamps = 0.0  # for progress bar\n",
    "with tqdm(total=info.duration, unit=\" audio seconds\") as pbar:\n",
    "    for i, segment in enumerate(segments, start=1):\n",
    "        full_txt.append(f\"{i}\\n{convert_seg(segment)}\")\n",
    "        pbar.update(segment.end - timestamps)\n",
    "        timestamps = segment.end\n",
    "    if timestamps < info.duration: # silence at the end of the audio\n",
    "        pbar.update(info.duration - timestamps)\n",
    "\n",
    "with open(\"file.srt\", mode=\"w\", encoding=\"UTF-8\") as f:\n",
    "    f.writelines(full_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[39m# 各セグメントからテキストを抽出\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfor\u001b[39;00m segment \u001b[39min\u001b[39;00m segments:\n\u001b[0;32m     14\u001b[0m     text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39msegment\u001b[39m.\u001b[39mtext \u001b[39m+\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[39m# 関数: 文末までの文章を結合\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\faster_whisper\\transcribe.py:403\u001b[0m, in \u001b[0;36mWhisperModel.generate_segments\u001b[1;34m(self, features, tokenizer, options, encoder_output)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[39mif\u001b[39;00m encoder_output \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    396\u001b[0m     encoder_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode(segment)\n\u001b[0;32m    398\u001b[0m (\n\u001b[0;32m    399\u001b[0m     result,\n\u001b[0;32m    400\u001b[0m     avg_logprob,\n\u001b[0;32m    401\u001b[0m     temperature,\n\u001b[0;32m    402\u001b[0m     compression_ratio,\n\u001b[1;32m--> 403\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_with_fallback(encoder_output, prompt, tokenizer, options)\n\u001b[0;32m    405\u001b[0m \u001b[39mif\u001b[39;00m options\u001b[39m.\u001b[39mno_speech_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    406\u001b[0m     \u001b[39m# no voice activity check\u001b[39;00m\n\u001b[0;32m    407\u001b[0m     should_skip \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mno_speech_prob \u001b[39m>\u001b[39m options\u001b[39m.\u001b[39mno_speech_threshold\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\faster_whisper\\transcribe.py:604\u001b[0m, in \u001b[0;36mWhisperModel.generate_with_fallback\u001b[1;34m(self, encoder_output, prompt, tokenizer, options)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    599\u001b[0m     kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    600\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbeam_size\u001b[39m\u001b[39m\"\u001b[39m: options\u001b[39m.\u001b[39mbeam_size,\n\u001b[0;32m    601\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpatience\u001b[39m\u001b[39m\"\u001b[39m: options\u001b[39m.\u001b[39mpatience,\n\u001b[0;32m    602\u001b[0m     }\n\u001b[1;32m--> 604\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mgenerate(\n\u001b[0;32m    605\u001b[0m     encoder_output,\n\u001b[0;32m    606\u001b[0m     [prompt],\n\u001b[0;32m    607\u001b[0m     length_penalty\u001b[39m=\u001b[39moptions\u001b[39m.\u001b[39mlength_penalty,\n\u001b[0;32m    608\u001b[0m     max_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length,\n\u001b[0;32m    609\u001b[0m     return_scores\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    610\u001b[0m     return_no_speech_prob\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    611\u001b[0m     suppress_blank\u001b[39m=\u001b[39moptions\u001b[39m.\u001b[39msuppress_blank,\n\u001b[0;32m    612\u001b[0m     suppress_tokens\u001b[39m=\u001b[39moptions\u001b[39m.\u001b[39msuppress_tokens,\n\u001b[0;32m    613\u001b[0m     max_initial_timestamp_index\u001b[39m=\u001b[39mmax_initial_timestamp_index,\n\u001b[0;32m    614\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    615\u001b[0m )[\u001b[39m0\u001b[39m]\n\u001b[0;32m    617\u001b[0m tokens \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39msequences_ids[\u001b[39m0\u001b[39m]\n\u001b[0;32m    619\u001b[0m \u001b[39m# Recover the average log prob from the returned score.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# インポートとWhisperモデルの設定\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model_size = \"large-v2\"\n",
    "\n",
    "# WhisperModelインスタンスの作成\n",
    "model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "# 音声ファイルをテキストに変換\n",
    "segments, info = model.transcribe(\"dvd.mp3\", beam_size=5)\n",
    "\n",
    "text = ''\n",
    "# 各セグメントからテキストを抽出\n",
    "for segment in segments:\n",
    "    text +=segment.text + ('\\n')\n",
    "\n",
    "# 関数: 文末までの文章を結合\n",
    "def join_sentences_until_period(text):\n",
    "    sentences = text.strip().split('\\n')\n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(sentences):\n",
    "        current_result = []\n",
    "        while i < len(sentences) and not sentences[i].strip().endswith('.'):\n",
    "            current_result.append(sentences[i].strip())\n",
    "            i += 1\n",
    "        if i < len(sentences):\n",
    "            current_result.append(sentences[i].strip())\n",
    "            i += 1\n",
    "        result.append(' '.join(current_result))\n",
    "    return result\n",
    "\n",
    "# 文末までの文章を結合\n",
    "output = join_sentences_until_period(text)\n",
    "\n",
    "# 翻訳モデルのインポートとインスタンス化\n",
    "from transformers import pipeline\n",
    "fugu_translator = pipeline('translation', model='staka/fugumt-en-ja')\n",
    "\n",
    "# 各行について翻訳を実行し、結果を出力\n",
    "for line in output:\n",
    "    # print(line)\n",
    "    print(fugu_translator(line)[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1467.919125/1467.919125 [02:19<00:00, 10.53 audio seconds/s]       \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m sentences \u001b[39m=\u001b[39m split_text_into_sentences(subtitle_text)\n\u001b[0;32m     67\u001b[0m \u001b[39m# 文を日本語に翻訳\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m translated_sentences \u001b[39m=\u001b[39m translate_sentences_to_japanese(sentences)\n\u001b[0;32m     70\u001b[0m \u001b[39m# 翻訳された文を結合\u001b[39;00m\n\u001b[0;32m     71\u001b[0m translated_subtitle \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(translated_sentences)\n",
      "Cell \u001b[1;32mIn[6], line 61\u001b[0m, in \u001b[0;36mtranslate_sentences_to_japanese\u001b[1;34m(sentences)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranslate_sentences_to_japanese\u001b[39m(sentences):\n\u001b[0;32m     60\u001b[0m     fugu_translator \u001b[39m=\u001b[39m pipeline(\u001b[39m'\u001b[39m\u001b[39mtranslation\u001b[39m\u001b[39m'\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstaka/fugumt-en-ja\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m     translations \u001b[39m=\u001b[39m [fugu_translator(sentence)[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtranslation_text\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences]\n\u001b[0;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m translations\n",
      "Cell \u001b[1;32mIn[6], line 61\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtranslate_sentences_to_japanese\u001b[39m(sentences):\n\u001b[0;32m     60\u001b[0m     fugu_translator \u001b[39m=\u001b[39m pipeline(\u001b[39m'\u001b[39m\u001b[39mtranslation\u001b[39m\u001b[39m'\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstaka/fugumt-en-ja\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m     translations \u001b[39m=\u001b[39m [fugu_translator(sentence)[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtranslation_text\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m sentences]\n\u001b[0;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m translations\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:367\u001b[0m, in \u001b[0;36mTranslationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    338\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[39m    Translate the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[39m          token ids of the translation.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:165\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    137\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[39m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    167\u001b[0m         \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m)\n\u001b[0;32m    168\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(el, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m args[\u001b[39m0\u001b[39m])\n\u001b[0;32m    169\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(res) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result)\n\u001b[0;32m    170\u001b[0m     ):\n\u001b[0;32m    171\u001b[0m         \u001b[39mreturn\u001b[39;00m [res[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\transformers\\pipelines\\base.py:1129\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[0;32m   1122\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[0;32m   1123\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1126\u001b[0m         )\n\u001b[0;32m   1127\u001b[0m     )\n\u001b[0;32m   1128\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\transformers\\pipelines\\base.py:1136\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1135\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1136\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[0;32m   1137\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1138\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\transformers\\pipelines\\base.py:1035\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1033\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1034\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m-> 1035\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[0;32m   1036\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1037\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:187\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m generate_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmax_length)\n\u001b[0;32m    186\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_inputs(input_length, generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m], generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m--> 187\u001b[0m output_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mgenerate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    188\u001b[0m out_b \u001b[39m=\u001b[39m output_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\transformers\\generation\\utils.py:1675\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1668\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1669\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1670\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_beams,\n\u001b[0;32m   1671\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1672\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1673\u001b[0m     )\n\u001b[0;32m   1674\u001b[0m     \u001b[39m# 13. run beam search\u001b[39;00m\n\u001b[1;32m-> 1675\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeam_search(\n\u001b[0;32m   1676\u001b[0m         input_ids,\n\u001b[0;32m   1677\u001b[0m         beam_scorer,\n\u001b[0;32m   1678\u001b[0m         logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[0;32m   1679\u001b[0m         stopping_criteria\u001b[39m=\u001b[39mstopping_criteria,\n\u001b[0;32m   1680\u001b[0m         pad_token_id\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mpad_token_id,\n\u001b[0;32m   1681\u001b[0m         eos_token_id\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39meos_token_id,\n\u001b[0;32m   1682\u001b[0m         output_scores\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39moutput_scores,\n\u001b[0;32m   1683\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m   1684\u001b[0m         synced_gpus\u001b[39m=\u001b[39msynced_gpus,\n\u001b[0;32m   1685\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1686\u001b[0m     )\n\u001b[0;32m   1688\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mBEAM_SAMPLE:\n\u001b[0;32m   1689\u001b[0m     \u001b[39m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   1690\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(generation_config)\n",
      "File \u001b[1;32mc:\\Users\\atusi\\anaconda3\\envs\\takara\\lib\\site-packages\\transformers\\generation\\utils.py:3014\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3010\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   3012\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m-> 3014\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\n\u001b[0;32m   3015\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs,\n\u001b[0;32m   3016\u001b[0m     return_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   3017\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[0;32m   3018\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   3019\u001b[0m )\n\u001b[0;32m   3021\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   3022\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # 必要なライブラリをインポート\n",
    "# import faster_whisper\n",
    "# import math\n",
    "# from tqdm import tqdm\n",
    "# from faster_whisper.transcribe import Segment\n",
    "# from transformers import pipeline\n",
    "\n",
    "# # Whisperモデルを初期化\n",
    "# model = faster_whisper.WhisperModel(\"large-v2\", device=\"cuda\")\n",
    "\n",
    "# # 音声ファイルをテキストに変換する関数\n",
    "# def transcribe_audio(audio_file):\n",
    "#     segments, info = model.transcribe(audio_file)\n",
    "#     return segments, info\n",
    "\n",
    "# # セグメントをSRT形式の文字列に変換する関数\n",
    "# def convert_to_srt(segment: Segment, index: int) -> str:\n",
    "#     return f\"{index}\\n{convert_to_hms(segment.start)} --> {convert_to_hms(segment.end)}\\n{segment.text.lstrip()}\\n\\n\"\n",
    "\n",
    "# # タイムスタンプをHH:MM:SS,mmm形式に変換する関数\n",
    "# def convert_to_hms(seconds: float) -> str:\n",
    "#     hours, remainder = divmod(seconds, 3600)\n",
    "#     minutes, seconds = divmod(remainder, 60)\n",
    "#     milliseconds = math.floor((seconds % 1) * 1000)\n",
    "#     output = f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02},{milliseconds:03}\"\n",
    "#     return output\n",
    "\n",
    "# # 日本語への翻訳を行う関数\n",
    "# def translate_to_japanese(text):\n",
    "#     fugu_translator = pipeline('translation', model='staka/fugumt-en-ja')\n",
    "#     return fugu_translator(text)[0]['translation_text']\n",
    "\n",
    "# # 音声ファイルをテキストに変換\n",
    "# segments, info = transcribe_audio(\"audio.webm\")\n",
    "\n",
    "# # SRT形式の字幕を作成\n",
    "# srt_subtitle = []\n",
    "# timestamps = 0.0\n",
    "\n",
    "# with tqdm(total=info.duration, unit=\" audio seconds\") as pbar:\n",
    "#     for i, segment in enumerate(segments, start=1):\n",
    "#         srt_subtitle.append(convert_to_srt(segment, i))\n",
    "#         pbar.update(segment.end - timestamps)\n",
    "#         timestamps = segment.end\n",
    "#     if timestamps < info.duration:  # オーディオの最後に無音がある場合\n",
    "#         pbar.update(info.duration - timestamps)\n",
    "\n",
    "# # 字幕テキストを結合\n",
    "# subtitle_text = \"\\n\".join(srt_subtitle)\n",
    "\n",
    "# # # 字幕を日本語に翻訳\n",
    "# # translated_subtitle = translate_to_japanese(subtitle_text)\n",
    "# # テキストを文ごとに分割する関数\n",
    "# def split_text_into_sentences(text):\n",
    "#     sentences = text.split('\\n')\n",
    "#     return sentences\n",
    "\n",
    "# # 日本語への翻訳を行う関数\n",
    "# def translate_sentences_to_japanese(sentences):\n",
    "#     fugu_translator = pipeline('translation', model='staka/fugumt-en-ja')\n",
    "#     translations = [fugu_translator(sentence)[0]['translation_text'] for sentence in sentences]\n",
    "#     return translations\n",
    "\n",
    "# # テキストを文ごとに分割\n",
    "# print(\"分割中\")\n",
    "# sentences = split_text_into_sentences(subtitle_text)\n",
    "\n",
    "\n",
    "# # 文を日本語に翻訳\n",
    "# print(\"翻訳中\")\n",
    "# translated_sentences = translate_sentences_to_japanese(sentences)\n",
    "\n",
    "# # 翻訳された文を結合\n",
    "# print(\"統合中\")\n",
    "# translated_subtitle = '\\n'.join(translated_sentences)\n",
    "\n",
    "\n",
    "# # 翻訳された字幕をファイルに保存\n",
    "# print(\"保存中\")\n",
    "# with open(\"translated_subtitle.srt\", mode=\"w\", encoding=\"UTF-8\") as f:\n",
    "#     f.write(translated_subtitle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_to_srt_time(seconds):\n",
    "    hours, remainder = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    milliseconds = int((seconds % 1) * 1000)\n",
    "    seconds = int(seconds)\n",
    "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{milliseconds:03d}\"\n",
    "\n",
    "def convert_txt_to_srt(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as txt_file:\n",
    "        lines = txt_file.readlines()\n",
    "\n",
    "    srt_lines = []\n",
    "    count = 1\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split('] ')\n",
    "        if len(parts) != 2:\n",
    "            continue\n",
    "\n",
    "        time_part = parts[0][1:-1]  # Remove '[' and ']'\n",
    "\n",
    "        # Check if 's' is present and remove it\n",
    "        if 's' in time_part:\n",
    "            time_part = time_part.replace('s', '')\n",
    "\n",
    "        start_time, end_time = time_part.split(' -> ')\n",
    "\n",
    "        # Convert seconds to SRT time format\n",
    "        start_time = seconds_to_srt_time(float(start_time))\n",
    "        end_time = seconds_to_srt_time(float(end_time))\n",
    "\n",
    "        srt_lines.append(f\"{count}\\n{start_time} --> {end_time}\\n{parts[1]}\\n\\n\")\n",
    "        count += 1\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as srt_file:\n",
    "        srt_file.writelines(srt_lines)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_txt_file = \"input.txt\"\n",
    "    output_srt_file = \"output5.srt\"\n",
    "    convert_txt_to_srt(input_txt_file, output_srt_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9/18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# モデルとトークナイザの読み込み\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "\n",
    "# 入力と出力のsrtファイル名を指定\n",
    "input_srt_file = \"input_subtitle.srt\"\n",
    "output_srt_file = \"output_subtitle.srt\"\n",
    "\n",
    "# srtファイルを読み取る関数\n",
    "def read_srt_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "    return lines\n",
    "\n",
    "# srtファイルを書き込む関数\n",
    "def write_srt_file(file_path, lines):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "# srtファイルを読み取り、翻訳して結果を新しいsrtファイルに書き込む\n",
    "def translate_srt_and_write(input_file, output_file):\n",
    "    srt_lines = read_srt_file(input_file)\n",
    "    translated_lines = []\n",
    "    \n",
    "    for line in srt_lines:\n",
    "        line = line.strip()\n",
    "        if line.isdigit():\n",
    "            # 字幕IDの行はそのまま追加\n",
    "            translated_lines.append(line)\n",
    "        elif re.match(r\"\\d+:\\d+:\\d+,\\d+ --> \\d+:\\d+:\\d+,\\d+\", line):\n",
    "            # 時間情報の行もそのまま追加\n",
    "            translated_lines.append(line)\n",
    "        elif line:\n",
    "            # テキスト行を翻訳\n",
    "            translated_text = translate_to_japanese(line)\n",
    "            translated_lines.append(translated_text)\n",
    "        else:\n",
    "            # 空行はそのまま追加\n",
    "            translated_lines.append(line)\n",
    "\n",
    "    # 翻訳結果を新しいsrtファイルに書き込む\n",
    "    write_srt_file(output_file, translated_lines)\n",
    "\n",
    "# テキストを翻訳する関数\n",
    "def translate_to_japanese(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512)\n",
    "    translated_tokens = model.generate(\n",
    "        **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"jpn_Jpan\"], max_length=512\n",
    "    )\n",
    "    translated_text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "    return translated_text\n",
    "\n",
    "# srtファイルの翻訳と出力\n",
    "translate_srt_and_write(input_srt_file, output_srt_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目標座標は：x= 1000 , y= 0 です\n",
      "目標座標は：x= 1000 , y= 1000 です\n",
      "目標座標は：x= 0 , y= 1000 です\n",
      "目標座標は：x= 0 , y= 0 です\n"
     ]
    }
   ],
   "source": [
    "waypoint = [[1000,0],[1000,1000],[0,1000],[0,0]]\n",
    "for wayp_xnum in range(len(waypoint)):\n",
    "    print(\"目標座標は：x=\",waypoint[wayp_xnum][0],\", y=\",waypoint[wayp_xnum][1], \"です\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(waypoint[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
